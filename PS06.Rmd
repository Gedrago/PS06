---
title: "STAT/MATH 495: Problem Set 06"
author: "MERON GEDRAGO"
date: "2017-10-17"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
library(dplyr)
library(gridExtra)
```





# Collaboration

Please indicate who you collaborated with on this assignment: 


# Setup

Define truth, which again we know for the purposes of this assignment, but in
practice we won't:

* the true function f(x) i.e. the signal
* the true epsilon i.e. the noise, which in this case is Normal$(0, sd=\sigma)$.
Hence the standard deviation $\sigma$ determines the amount of noise.

```{r}
f <- function(x) {
  x^2
}
sigma <- 0.3
```

This is the target point we'll be trying to predict: $(0.95, f(0.95)) = (0.95, 0.95^2) = (0.95, 0.9025)$, Thus, the test set is just `x=0.95`

```{r}
x0 <- 0.95
test_set <- data_frame(x=x0)
```

This function generates a random sample of size $n$; think of this as a "get new
data" function. Random in terms of both:

* (New) the predictor x (uniform on [0,1])
* the amount of noise $\epsilon$

```{r}
generate_sample <- function(f, n, sigma) {
  sample <- data_frame(
    x = runif(n = n, min = 0, max = 1),
    f_x = f(x),
    epsilon = rnorm(n = n, mean = 0, sd = sigma),
    y = f_x + epsilon
  )
  # Recall: We don't observe f(x) and epsilon, just (x, y)
  sample <- sample %>% 
    select(x, y) 
  return(sample)
}

```

Define

* The number $n$ of observations $(x_i, y_i)$ in each sample. In the handout,
$n=100$ to keep plots uncrowded. Here we boost to $n=500$
* Number of samples of size $n$ to consider


# Computation

We then construct the two models to predict the y value at x=0.95 using df=2 and df=99. 
```{r, include=FALSE}
for(i in 1:50) {
   sampled_points <-  generate_sample(f, 500, sigma)
    fitted_df_99 <- smooth.spline(x=sampled_points$x, y=sampled_points$y, df=99)
    fitted_df_2 <- smooth.spline(x=sampled_points$x, y=sampled_points$y, df=2)  
    fitted_data2 <- augment(fitted_df_2)
    fitted_data99 <- augment(fitted_df_99)
}
predictedf2 <- predict(fitted_df_2,test_set)
as.data.frame(predictedf2)
predictedf99 <- predict(fitted_df_99, test_set)
as.data.frame(predictedf99)
```


```{r, include=FALSE}
#finding the irreducible error, bias and variance for the spline model with df=2
irrdf2 <- sigma^2
Biasdf2 <- (predictedf2$y - 0.9025)^2
Vardf2 <- var(fitted_data2$.fitted)
sum2 <- sum(irrdf2,Biasdf2,Vardf2)
framedf2 <- matrix(c("irreducible","   bias squared","  var","  sum",irrdf2,Biasdf2,Vardf2,sum2),nrow= 2, byrow = TRUE)
```


```{r, include=FALSE}
#finding the irreducible error, bias and variance for the spline model with df=99
irrdf99 <- sigma^2
Biasdf99 <- (predictedf99$y - 0.9025)^2
Vardf99 <- var(fitted_data99$.fitted)
sum99 <- sum(irrdf99,Biasdf99,Vardf99)
sum99
framedf99 <- matrix(c("irreducible  ","bias squared","  var","  sum",irrdf99,Biasdf99,Vardf99,sum99),nrow= 2, byrow = TRUE)

```



# Tables

As done in Lec 2.7, for both

* An `lm` regression AKA a `smooth.splines(x, y, df=2)` model fit 
* A `smooth.splines(x, y, df=99)` model fit 
s
output tables comparing:

|  MSE| bias_squared|   var| irreducible|   sum|
|----:|------------:|-----:|-----------:|-----:|
|     X|           X  |     X |      X |         X |

where `sum = bias_squared + var + irreducible`. You can created cleanly formatted tables like the one above by piping a data frame into `knitr::kable(digits=4)`.



```{r}

knitr::kable(framedf2,digits=4,caption= "output table of df =2 ", padding= 0)
framedf99 %>% knitr::kable(digits=4 , caption = "output table of df= 99")

```


# Analysis

**Questions**:

1. Based on the topics covered in Lec 2.7, name one possible "sanity check" for your results. Name another if you can.
1. In **two** sentences or less, give a rough sketch of what the procedure would
be to get the breakdown of $$\mbox{MSE}\left[\widehat{f}(x)\right]$$ for *all*
$x$ in this example, and not just for $$\mbox{MSE}\left[\widehat{f}(x_0)\right]
= \mbox{MSE}\left[\widehat{f}(0.95)\right]$$.
1. Which of the two models would you choose for predicting the point of interest and why?

**Answers**:

1. We can check whether that our values are correct by looking at the pattern of the bias variance trade off. We can see the bias is relatively higher in df=2 than in df=99. 
1.To find the MSE of all x, we can evaluate the bias of each point by finding the difference between the predicted and theoretic. Then, calculating the variance and adding all to get the MSE.
1.I would choose the model with the 99 degrees of freedom. Since we are focusing on one point, we want more accuracy which refers to lower bias. This leads us to prefer the second row where the variance is relatively higher and the bias is relatively lower. 
